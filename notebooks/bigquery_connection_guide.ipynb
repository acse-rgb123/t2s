{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Connection Guide\n",
    "\n",
    "This notebook provides a step-by-step guide to connect to BigQuery datasets, including the Spider 2 dataset and your own custom datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "1. **Google Cloud Account**: Sign up at https://cloud.google.com/\n",
    "2. **Google Cloud Project**: Create a project in the Google Cloud Console\n",
    "3. **BigQuery API**: Enable the BigQuery API in your project\n",
    "4. **Billing Account**: Link a billing account to your project (required for BigQuery)\n",
    "\n",
    "### Cost Considerations\n",
    "- BigQuery charges for query processing (first 1TB per month is free)\n",
    "- Public datasets like Spider 2 are free to query\n",
    "- Use the `dry_run` feature to estimate costs before running queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run this if not already installed)\n",
    "# !pip install google-cloud-bigquery google-auth pandas python-dotenv\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'backend'))\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Authentication\n",
    "\n",
    "### Method 1: Service Account (Recommended for Production)\n",
    "\n",
    "1. **Create a Service Account**:\n",
    "   - Go to Google Cloud Console ‚Üí IAM & Admin ‚Üí Service Accounts\n",
    "   - Click \"Create Service Account\"\n",
    "   - Give it a name and description\n",
    "   - Grant roles: `BigQuery Data Viewer`, `BigQuery Job User`\n",
    "\n",
    "2. **Download the JSON Key**:\n",
    "   - Click on your service account\n",
    "   - Go to \"Keys\" tab ‚Üí \"Add Key\" ‚Üí \"Create new key\" ‚Üí JSON\n",
    "   - Download and save the JSON file securely\n",
    "\n",
    "3. **Set Environment Variable**:\n",
    "   ```bash\n",
    "   export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/your/service-account-key.json\"\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using Service Account JSON file\n",
    "SERVICE_ACCOUNT_PATH = \"/path/to/your/service-account-key.json\"  # Update this path\n",
    "PROJECT_ID = \"your-google-cloud-project-id\"  # Update this\n",
    "\n",
    "# Check if service account file exists\n",
    "if os.path.exists(SERVICE_ACCOUNT_PATH):\n",
    "    print(f\"‚úì Service account file found: {SERVICE_ACCOUNT_PATH}\")\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = SERVICE_ACCOUNT_PATH\n",
    "    os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
    "else:\n",
    "    print(f\"‚ùå Service account file not found: {SERVICE_ACCOUNT_PATH}\")\n",
    "    print(\"Please update the SERVICE_ACCOUNT_PATH variable above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: User Authentication (Good for Development)\n",
    "\n",
    "1. **Install Google Cloud CLI**: https://cloud.google.com/sdk/docs/install\n",
    "2. **Authenticate**: Run `gcloud auth application-default login`\n",
    "3. **Set Project**: Run `gcloud config set project YOUR_PROJECT_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using gcloud CLI authentication\n",
    "# Uncomment and run this if you prefer user authentication\n",
    "\n",
    "# import subprocess\n",
    "# try:\n",
    "#     # Check if gcloud is authenticated\n",
    "#     result = subprocess.run(['gcloud', 'auth', 'list', '--filter=status:ACTIVE'], \n",
    "#                           capture_output=True, text=True)\n",
    "#     if result.returncode == 0 and result.stdout.strip():\n",
    "#         print(\"‚úì gcloud authentication found\")\n",
    "#         print(result.stdout)\n",
    "#     else:\n",
    "#         print(\"‚ùå No active gcloud authentication\")\n",
    "#         print(\"Run: gcloud auth application-default login\")\n",
    "# except FileNotFoundError:\n",
    "#     print(\"‚ùå gcloud CLI not found. Please install it first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Environment Variables with JSON Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Set credentials directly as environment variables\n",
    "# This is useful for deployment environments like Docker, Heroku, etc.\n",
    "\n",
    "# Example of setting credentials JSON directly\n",
    "# GOOGLE_CREDENTIALS_JSON = '''\n",
    "# {\n",
    "#   \"type\": \"service_account\",\n",
    "#   \"project_id\": \"your-project-id\",\n",
    "#   \"private_key_id\": \"...\",\n",
    "#   \"private_key\": \"...\",\n",
    "#   \"client_email\": \"...\",\n",
    "#   \"client_id\": \"...\",\n",
    "#   \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "#   \"token_uri\": \"https://oauth2.googleapis.com/token\"\n",
    "# }\n",
    "# '''\n",
    "\n",
    "# # Load from environment or .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('../.env')\n",
    "\n",
    "# credentials_json = os.getenv('GOOGLE_CREDENTIALS_JSON')\n",
    "# if credentials_json:\n",
    "#     print(\"‚úì Found credentials in environment variables\")\n",
    "# else:\n",
    "#     print(\"‚ùå No credentials found in environment variables\")\n",
    "\n",
    "print(\"Environment variables method ready (commented out for security)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Basic BigQuery Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our BigQuery client\n",
    "from data_connection.bigquery_client import BigQueryClient\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    # Initialize client\n",
    "    client = BigQueryClient(\n",
    "        project_id=PROJECT_ID,\n",
    "        service_account_path=SERVICE_ACCOUNT_PATH if os.path.exists(SERVICE_ACCOUNT_PATH) else None\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Connected to BigQuery project: {client.project_id}\")\n",
    "    \n",
    "    # Test with a simple query\n",
    "    test_query = \"\"\"\n",
    "    SELECT \n",
    "        'Hello BigQuery!' as message,\n",
    "        CURRENT_TIMESTAMP() as timestamp,\n",
    "        @@version as version\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nTesting basic query...\")\n",
    "    result = client.query(test_query)\n",
    "    print(\"‚úì Basic query successful:\")\n",
    "    display(result)\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"1. Check your project ID\")\n",
    "    print(\"2. Verify BigQuery API is enabled\")\n",
    "    print(\"3. Confirm authentication method is set up correctly\")\n",
    "    print(\"4. Ensure billing is enabled for your project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Explore Your Project's Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List datasets in your project\n",
    "try:\n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    # List datasets\n",
    "    datasets = list(client.client.list_datasets())\n",
    "    \n",
    "    if datasets:\n",
    "        print(f\"‚úì Found {len(datasets)} datasets in project '{client.project_id}':\")\n",
    "        for dataset in datasets:\n",
    "            print(f\"  - {dataset.dataset_id}\")\n",
    "            \n",
    "            # List tables in each dataset\n",
    "            tables = list(client.client.list_tables(dataset.reference))\n",
    "            if tables:\n",
    "                print(f\"    Tables ({len(tables)}): {[t.table_id for t in tables[:5]]}\")\n",
    "                if len(tables) > 5:\n",
    "                    print(f\"    ... and {len(tables) - 5} more\")\n",
    "            else:\n",
    "                print(\"    No tables found\")\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"No datasets found in project '{client.project_id}'\")\n",
    "        print(\"You can create datasets in the BigQuery console or programmatically\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"‚ùå Failed to list datasets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Access Public Datasets (Spider 2 Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Spider 2 public dataset\n",
    "try:\n",
    "    print(\"Accessing Spider 2 public dataset...\")\n",
    "    \n",
    "    # List Spider 2 tables\n",
    "    spider_tables = client.list_spider2_tables()\n",
    "    \n",
    "    print(f\"‚úì Spider 2 dataset accessed successfully\")\n",
    "    print(f\"Found {len(spider_tables)} tables\")\n",
    "    print(\"\\nFirst 10 tables:\")\n",
    "    for table in spider_tables[:10]:\n",
    "        print(f\"  - {table}\")\n",
    "    \n",
    "    if len(spider_tables) > 10:\n",
    "        print(f\"  ... and {len(spider_tables) - 10} more\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"‚ùå Failed to access Spider 2 dataset: {e}\")\n",
    "    print(\"Note: Public datasets should be accessible without special permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Query Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate query costs before running expensive queries\n",
    "if 'spider_tables' in locals() and len(spider_tables) > 0:\n",
    "    sample_table = spider_tables[0]\n",
    "    \n",
    "    # Create a sample query\n",
    "    sample_query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `spider2-public-data.spider2_1_0.{sample_table}`\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Estimating cost for query on table: {sample_table}\")\n",
    "        \n",
    "        # Dry run to estimate cost\n",
    "        cost_estimate = client.validate_query(sample_query)\n",
    "        \n",
    "        print(\"\\n‚úì Cost Estimation:\")\n",
    "        print(f\"  Query is valid: {cost_estimate['valid']}\")\n",
    "        \n",
    "        bytes_processed = cost_estimate.get('total_bytes_processed', 0)\n",
    "        if bytes_processed:\n",
    "            gb_processed = bytes_processed / (1024**3)\n",
    "            estimated_cost = gb_processed * 5  # $5 per TB = $0.005 per GB\n",
    "            \n",
    "            print(f\"  Bytes to process: {bytes_processed:,}\")\n",
    "            print(f\"  GB to process: {gb_processed:.4f}\")\n",
    "            print(f\"  Estimated cost: ${estimated_cost:.6f} USD\")\n",
    "        else:\n",
    "            print(\"  Cost: Free (likely cached or very small)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cost estimation failed: {e}\")\nelse:\n",
    "    print(\"‚ö† No Spider 2 tables available for cost estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Execute Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a safe, small query\n",
    "if 'sample_table' in locals():\n",
    "    try:\n",
    "        print(f\"Executing sample query on {sample_table}...\")\n",
    "        \n",
    "        # Get sample data\n",
    "        sample_data = client.sample_table_data(sample_table, limit=5)\n",
    "        \n",
    "        print(f\"\\n‚úì Query executed successfully\")\n",
    "        print(f\"Table: {sample_table}\")\n",
    "        print(f\"Rows returned: {len(sample_data)}\")\n",
    "        print(f\"Columns: {list(sample_data.columns)}\")\n",
    "        \n",
    "        print(\"\\nSample data:\")\n",
    "        display(sample_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Query execution failed: {e}\")\nelse:\n",
    "    print(\"‚ö† No table available for sample query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Working with Your Own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a dataset and table (optional)\n",
    "# This is commented out to avoid creating resources accidentally\n",
    "\n",
    "create_example = False  # Set to True if you want to create example data\n",
    "\n",
    "if create_example:\n",
    "    try:\n",
    "        from google.cloud import bigquery\n",
    "        \n",
    "        dataset_id = f\"{client.project_id}.example_dataset\"\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = bigquery.Dataset(dataset_id)\n",
    "        dataset.location = \"US\"\n",
    "        dataset = client.client.create_dataset(dataset, exists_ok=True)\n",
    "        print(f\"‚úì Created dataset: {dataset.dataset_id}\")\n",
    "        \n",
    "        # Create a simple table with sample data\n",
    "        table_id = f\"{dataset_id}.sample_table\"\n",
    "        \n",
    "        # Define schema\n",
    "        schema = [\n",
    "            bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"REQUIRED\"),\n",
    "            bigquery.SchemaField(\"name\", \"STRING\", mode=\"REQUIRED\"),\n",
    "            bigquery.SchemaField(\"email\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "        ]\n",
    "        \n",
    "        table = bigquery.Table(table_id, schema=schema)\n",
    "        table = client.client.create_table(table, exists_ok=True)\n",
    "        print(f\"‚úì Created table: {table.table_id}\")\n",
    "        \n",
    "        # Insert sample data\n",
    "        rows_to_insert = [\n",
    "            {\"id\": 1, \"name\": \"Alice\", \"email\": \"alice@example.com\", \"created_at\": \"2024-01-01 10:00:00\"},\n",
    "            {\"id\": 2, \"name\": \"Bob\", \"email\": \"bob@example.com\", \"created_at\": \"2024-01-02 11:00:00\"},\n",
    "            {\"id\": 3, \"name\": \"Charlie\", \"email\": \"charlie@example.com\", \"created_at\": \"2024-01-03 12:00:00\"},\n",
    "        ]\n",
    "        \n",
    "        errors = client.client.insert_rows_json(table, rows_to_insert)\n",
    "        if errors == []:\n",
    "            print(\"‚úì Sample data inserted successfully\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to insert data: {errors}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create example dataset: {e}\")\nelse:\n",
    "    print(\"Example dataset creation skipped (set create_example=True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Advanced BigQuery Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced BigQuery features\n",
    "\n",
    "# 1. Parameterized queries (safer than string formatting)\n",
    "def run_parameterized_query():\n",
    "    try:\n",
    "        from google.cloud import bigquery\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            @message as greeting,\n",
    "            @number as lucky_number,\n",
    "            CURRENT_TIMESTAMP() as query_time\n",
    "        \"\"\"\n",
    "        \n",
    "        job_config = bigquery.QueryJobConfig(\n",
    "            query_parameters=[\n",
    "                bigquery.ScalarQueryParameter(\"message\", \"STRING\", \"Hello from parameterized query!\"),\n",
    "                bigquery.ScalarQueryParameter(\"number\", \"INTEGER\", 42),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        query_job = client.client.query(query, job_config=job_config)\n",
    "        result = query_job.result().to_dataframe()\n",
    "        \n",
    "        print(\"‚úì Parameterized query executed:\")\n",
    "        display(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Parameterized query failed: {e}\")\n",
    "\n",
    "# 2. Query with different output formats\n",
    "def demonstrate_output_formats():\n",
    "    try:\n",
    "        simple_query = \"SELECT 'test' as column1, 123 as column2\"\n",
    "        \n",
    "        # As DataFrame\n",
    "        df_result = client.query(simple_query, to_dataframe=True)\n",
    "        print(\"DataFrame result:\")\n",
    "        print(type(df_result))\n",
    "        display(df_result)\n",
    "        \n",
    "        # As list of dictionaries\n",
    "        dict_result = client.query(simple_query, to_dataframe=False)\n",
    "        print(\"\\nDictionary result:\")\n",
    "        print(type(dict_result))\n",
    "        print(dict_result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Output format demo failed: {e}\")\n",
    "\n",
    "print(\"Running advanced features demo...\")\n",
    "run_parameterized_query()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "demonstrate_output_formats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Connection Management and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate proper connection management\n",
    "\n",
    "# 1. Using context manager (recommended)\n",
    "def demonstrate_context_manager():\n",
    "    try:\n",
    "        # This ensures automatic cleanup\n",
    "        with BigQueryClient(project_id=PROJECT_ID) as temp_client:\n",
    "            result = temp_client.query(\"SELECT 'Context manager test' as message\")\n",
    "            print(\"‚úì Context manager query successful:\")\n",
    "            display(result)\n",
    "        print(\"‚úì Connection automatically closed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Context manager demo failed: {e}\")\n",
    "\n",
    "# 2. Manual cleanup\n",
    "def demonstrate_manual_cleanup():\n",
    "    temp_client = None\n",
    "    try:\n",
    "        temp_client = BigQueryClient(project_id=PROJECT_ID)\n",
    "        result = temp_client.query(\"SELECT 'Manual cleanup test' as message\")\n",
    "        print(\"‚úì Manual cleanup query successful:\")\n",
    "        display(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Manual cleanup demo failed: {e}\")\n",
    "    finally:\n",
    "        if temp_client:\n",
    "            temp_client.close()\n",
    "            print(\"‚úì Connection manually closed\")\n",
    "\n",
    "print(\"Demonstrating connection management...\")\n",
    "# Note: Context manager may not work with our current implementation\n",
    "# demonstrate_context_manager()\n",
    "# print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "demonstrate_manual_cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the main client connection\n",
    "try:\n",
    "    if 'client' in locals():\n",
    "        client.close()\n",
    "        print(\"‚úì Main BigQuery client connection closed\")\nexcept Exception as e:\n",
    "    print(f\"Warning: Error during cleanup: {e}\")\n",
    "\n",
    "print(\"\\nüéâ BigQuery connection guide completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. **Authentication Methods**: Service account, user credentials, environment variables\n",
    "2. **Basic Connections**: How to connect and test BigQuery access\n",
    "3. **Dataset Exploration**: Listing datasets and tables\n",
    "4. **Public Datasets**: Accessing Spider 2 and other public data\n",
    "5. **Cost Management**: Estimating query costs before execution\n",
    "6. **Query Execution**: Running queries and handling results\n",
    "7. **Advanced Features**: Parameterized queries, output formats\n",
    "8. **Best Practices**: Connection management and cleanup\n",
    "\n",
    "### Troubleshooting Common Issues:\n",
    "\n",
    "| Error | Solution |\n",
    "|-------|----------|\n",
    "| Authentication failed | Check service account permissions, verify JSON key |\n",
    "| Project not found | Verify project ID, ensure project exists |\n",
    "| BigQuery API not enabled | Enable BigQuery API in Google Cloud Console |\n",
    "| Billing not enabled | Link a billing account to your project |\n",
    "| Permission denied | Add BigQuery roles to your service account |\n",
    "| Quota exceeded | Check your BigQuery quotas and limits |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Explore Spider 2**: Use the `test_spider2_connection.ipynb` notebook\n",
    "2. **Build Text-to-SQL**: Try the other notebooks for SQL generation\n",
    "3. **Create Custom Datasets**: Upload your own data to BigQuery\n",
    "4. **Optimize Queries**: Learn BigQuery best practices for performance\n",
    "5. **Monitor Costs**: Set up billing alerts and query monitoring\n",
    "\n",
    "### Useful Resources:\n",
    "\n",
    "- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)\n",
    "- [BigQuery Python Client](https://googleapis.dev/python/bigquery/latest/)\n",
    "- [BigQuery Pricing](https://cloud.google.com/bigquery/pricing)\n",
    "- [BigQuery Public Datasets](https://cloud.google.com/bigquery/public-data)\n",
    "- [Spider 2 Dataset](https://spider2-sql.github.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}