{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Service Testing Notebook\n",
    "\n",
    "This notebook tests the conversation functionality using Gemini for chat interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'backend'))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Conversation Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversation.services import ConversationService\n",
    "\n",
    "# Initialize conversation service\n",
    "chat_service = ConversationService()\n",
    "\n",
    "# Test basic conversation\n",
    "response = chat_service.generate_response(\n",
    "    user_message=\"Hello! I need help understanding my database.\"\n",
    ")\n",
    "\n",
    "print(\"User: Hello! I need help understanding my database.\")\n",
    "print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Conversation with History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a conversation with history\n",
    "conversation_history = [\n",
    "    {\"role\": \"user\", \"content\": \"I have a database with users and orders tables\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Great! I can help you query your users and orders data. What would you like to find out?\"},\n",
    "    {\"role\": \"user\", \"content\": \"I want to find my best customers\"}\n",
    "]\n",
    "\n",
    "response_with_context = chat_service.generate_response(\n",
    "    user_message=\"How do I define 'best' customers?\",\n",
    "    conversation_history=conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\n--- Conversation with Context ---\")\n",
    "for msg in conversation_history:\n",
    "    print(f\"{msg['role'].capitalize()}: {msg['content']}\")\n",
    "\n",
    "print(f\"User: How do I define 'best' customers?\")\n",
    "print(f\"Assistant: {response_with_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming response\n",
    "print(\"\\n--- Streaming Response Test ---\")\n",
    "print(\"User: Explain how SQL JOIN operations work\")\n",
    "print(\"Assistant: \", end=\"\")\n",
    "\n",
    "try:\n",
    "    for chunk in chat_service.stream_response(\n",
    "        user_message=\"Explain how SQL JOIN operations work\",\n",
    "        temperature=0.6\n",
    "    ):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    print(\"\\n\")  # New line after streaming\nexcept Exception as e:\n",
    "    print(f\"\\nStreaming error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Async Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def test_async_conversation():\n",
    "    response = await chat_service.generate_response_async(\n",
    "        user_message=\"What are some common database optimization techniques?\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Run async test\n",
    "async_response = await test_async_conversation()\n",
    "print(\"\\n--- Async Response ---\")\n",
    "print(f\"User: What are some common database optimization techniques?\")\n",
    "print(f\"Assistant: {async_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Conversation Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test various conversation scenarios\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"message\": \"I'm getting an error when running my SQL query\",\n",
    "        \"description\": \"Error troubleshooting\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"Can you help me understand what this query result means?\",\n",
    "        \"description\": \"Result interpretation\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"What's the difference between INNER JOIN and LEFT JOIN?\",\n",
    "        \"description\": \"Educational question\"\n",
    "    },\n",
    "    {\n",
    "        \"message\": \"I need to create a report showing monthly sales trends\",\n",
    "        \"description\": \"Business requirement\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n--- Scenario {i}: {scenario['description']} ---\")\n",
    "    print(f\"User: {scenario['message']}\")\n",
    "    \n",
    "    try:\n",
    "        response = chat_service.generate_response(\n",
    "            user_message=scenario['message'],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        print(f\"Assistant: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Temperature Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different temperature settings\n",
    "test_message = \"Give me some creative ideas for analyzing customer data\"\n",
    "temperatures = [0.2, 0.7, 1.0]\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n--- Temperature: {temp} ---\")\n",
    "    print(f\"User: {test_message}\")\n",
    "    \n",
    "    try:\n",
    "        response = chat_service.generate_response(\n",
    "            user_message=test_message,\n",
    "            temperature=temp\n",
    "        )\n",
    "        print(f\"Assistant: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Flow Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a full conversation flow\n",
    "def simulate_conversation():\n",
    "    conversation = []\n",
    "    \n",
    "    user_messages = [\n",
    "        \"Hi, I'm new to SQL and need help with my e-commerce database\",\n",
    "        \"I have tables for customers, orders, and products. What should I analyze first?\",\n",
    "        \"How do I find out which products are selling best?\",\n",
    "        \"Can you help me write a query for that?\"\n",
    "    ]\n",
    "    \n",
    "    for user_msg in user_messages:\n",
    "        print(f\"\\nUser: {user_msg}\")\n",
    "        \n",
    "        # Generate response with conversation history\n",
    "        response = chat_service.generate_response(\n",
    "            user_message=user_msg,\n",
    "            conversation_history=conversation,\n",
    "            temperature=0.6\n",
    "        )\n",
    "        \n",
    "        print(f\"Assistant: {response}\")\n",
    "        \n",
    "        # Add to conversation history\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Run the simulation\n",
    "print(\"\\n=== Conversation Flow Simulation ===\")\n",
    "simulate_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}